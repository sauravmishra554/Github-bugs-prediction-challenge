{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edaf8032e04e435d9f8cd4adb289a30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_617bbf1551b34919ae77ed9c1166185f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b10b26842b544ec7872b79985f006f12",
              "IPY_MODEL_9c08a46dff3c4771a1937a67c1363bb2"
            ]
          }
        },
        "617bbf1551b34919ae77ed9c1166185f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b10b26842b544ec7872b79985f006f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e741c555d77540368e251ce61f5eaee1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62de3863aeff4b51a540be04fffcb849"
          }
        },
        "9c08a46dff3c4771a1937a67c1363bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_903a18131696402c84ff4c07dcad8c75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 934kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13a5d3f29f054031b7d0c0ff7f00853b"
          }
        },
        "e741c555d77540368e251ce61f5eaee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62de3863aeff4b51a540be04fffcb849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "903a18131696402c84ff4c07dcad8c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13a5d3f29f054031b7d0c0ff7f00853b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18e7c4123ebf42ef8f920de025b71469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce345b412f1b45a4bb6333ec5fb356b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_94bcf4eeaa3642bc9eee21b7b5b8be85",
              "IPY_MODEL_5be013653ba74945a87205117e285b3d"
            ]
          }
        },
        "ce345b412f1b45a4bb6333ec5fb356b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94bcf4eeaa3642bc9eee21b7b5b8be85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_583d99895af14b818fd1792409b24aa2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d9e497f65b44eb5afb41fa25baf6506"
          }
        },
        "5be013653ba74945a87205117e285b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78ebf0a46b79437b98855cb9f16c6a84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d282d647ec354632bf0242e66cf650b6"
          }
        },
        "583d99895af14b818fd1792409b24aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d9e497f65b44eb5afb41fa25baf6506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78ebf0a46b79437b98855cb9f16c6a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d282d647ec354632bf0242e66cf650b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28643af078e94109976e7099e0c2b85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e6f810d00389465cbd7732acd96ab922",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2bccf35423974cea91da0ccf1a6bc97e",
              "IPY_MODEL_f15cf09fe52f445baec80c01a1e4a11d"
            ]
          }
        },
        "e6f810d00389465cbd7732acd96ab922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bccf35423974cea91da0ccf1a6bc97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cec280df1f29444d92a418ef03236699",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7972f6b3116e4f62849d189418d34e7c"
          }
        },
        "f15cf09fe52f445baec80c01a1e4a11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ad6899c374b4f3880220abebe767b42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 1.78kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9655fb9b5be74b1297802db698df6ab1"
          }
        },
        "cec280df1f29444d92a418ef03236699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7972f6b3116e4f62849d189418d34e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ad6899c374b4f3880220abebe767b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9655fb9b5be74b1297802db698df6ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a52299719a224fffa0d9bb4706940da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8636673094284870a93f301176d89bb1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64cf2ac471d94f26a69e4eb2ec995601",
              "IPY_MODEL_982fddeee5a04a738089dd33a5b9bae3"
            ]
          }
        },
        "8636673094284870a93f301176d89bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64cf2ac471d94f26a69e4eb2ec995601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f1c5c13bbed444388b2978c8e0376b2f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e33c74beb1048aaa9868a37ac9d89b7"
          }
        },
        "982fddeee5a04a738089dd33a5b9bae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41e37f135cba4ac9abd85a11aded26c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:07&lt;00:00, 67.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ccf988772e94dbd922e092abbf371a8"
          }
        },
        "f1c5c13bbed444388b2978c8e0376b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e33c74beb1048aaa9868a37ac9d89b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41e37f135cba4ac9abd85a11aded26c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ccf988772e94dbd922e092abbf371a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0B4VUTdBO7Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bRmP9XbBYed"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGDXfBQ1BwmA"
      },
      "source": [
        "# to increase no. of rows and column visibility in outputs\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsSc5PHFd4Sd"
      },
      "source": [
        "train= pd.read_json(\"/content/drive/My Drive/github bug data/embold_train.json\").reset_index(drop=True)\n",
        "test=pd.read_json(\"/content/drive/My Drive/github bug data/embold_test.json\").reset_index(drop=True)\n",
        "train_ex=pd.read_json(\"/content/drive/My Drive/github bug data/embold_train_extra.json\").reset_index(drop=True)\n",
        "# sub=pd.read_csv(\"../input/github-bug-prediction/sample submission.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIl6e72Jd8Ku",
        "outputId": "1406f032-9337-4488-acb2-6e63a3447f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train.head()\n",
        "test.head()\n",
        "# train_ex.head()\n",
        "train=pd.concat([train,train_ex],axis=0)\n",
        "# sub.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>y-zoom piano roll</td>\n",
              "      <td>a y-zoom on the piano roll would be useful.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buggy behavior in selection</td>\n",
              "      <td>! screenshot from 2016-02-23 21 27 40  https:/...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>auto update feature</td>\n",
              "      <td>hi,\\r \\r great job so far, @saenzramiro ! : \\r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>filter out noisy endpoints in logs</td>\n",
              "      <td>i think we should stop logging requests to:\\r ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>enable pid on / pid off alarm actions for ardu...</td>\n",
              "      <td>expected behavior\\r alarm actions pid on and p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                                               body  label\n",
              "0                                  y-zoom piano roll        a y-zoom on the piano roll would be useful.      1\n",
              "1                        buggy behavior in selection  ! screenshot from 2016-02-23 21 27 40  https:/...      0\n",
              "2                                auto update feature  hi,\\r \\r great job so far, @saenzramiro ! : \\r...      1\n",
              "3                 filter out noisy endpoints in logs  i think we should stop logging requests to:\\r ...      1\n",
              "4  enable pid on / pid off alarm actions for ardu...  expected behavior\\r alarm actions pid on and p...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>config question  path-specific environment var...</td>\n",
              "      <td>issue description or question\\r \\r hey @artemg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crash indien vol</td>\n",
              "      <td>de simulator crasht als hij vol zit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unable to mine rocks</td>\n",
              "      <td>sarkasmo starting today, when i hit enter  act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>not all whitelists are processed</td>\n",
              "      <td>create following rules... order of creation is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>add ctx menu for idafree 70 and idafree 5</td>\n",
              "      <td>associated with .dll, .dll_, .exe, .exe_, .sc,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                                               body\n",
              "0  config question  path-specific environment var...  issue description or question\\r \\r hey @artemg...\n",
              "1                                   crash indien vol                de simulator crasht als hij vol zit\n",
              "2                               unable to mine rocks  sarkasmo starting today, when i hit enter  act...\n",
              "3                   not all whitelists are processed  create following rules... order of creation is...\n",
              "4          add ctx menu for idafree 70 and idafree 5  associated with .dll, .dll_, .exe, .exe_, .sc,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXlyN6s3DPeM"
      },
      "source": [
        "train['text']=train['title']+' '+train['body']\n",
        "test['text']=test['title']+' '+test['body']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "279O9F7-DqIN"
      },
      "source": [
        "import re\n",
        "def rem_links(text):\n",
        "  text_list=text.split()\n",
        "  text_list=[w for w in text_list if not (w.startswith('http') or '@' in w)]\n",
        "  return ' '.join(text_list)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47vfSEvnDvKP"
      },
      "source": [
        "train['text']=train['text'].apply(rem_links)\n",
        "test['text']=test['text'].apply(rem_links)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSYkkeZoDztH",
        "outputId": "6134cc48-31fd-4247-9558-caddf3003e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# import re\n",
        "# # #cleaning text\n",
        "# # train['body']=train['body'].str.replace('_',' ')\n",
        "# # test['body']=test['body'].str.replace('_',' ')\n",
        "train['text']=train['text'].str.replace(r'\\\\r',r'')\n",
        "test['text']=test['text'].str.replace(r'\\\\r',r'')\n",
        "train.loc[2,'text']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    auto update feature hi,  great job so far, ! :...\n",
              "2    add multilang support for timeago.js currently...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrQnw0ScFUZF"
      },
      "source": [
        "train=train.drop(['title','body'],axis=1)\n",
        "test=test.drop(['title','body'],axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSXD-cN1-bHi",
        "outputId": "5d9378a0-44ec-4352-f429-8d6b4d91c3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 43.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 52.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0VHJ9Q-qNi"
      },
      "source": [
        "import torch \n",
        "from transformers import RobertaTokenizer,RobertaModel,get_linear_schedule_with_warmup\n",
        "import transformers \n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from transformers import AdamW\n",
        "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
        "import os \n",
        "import random"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4yEbneGXn3O"
      },
      "source": [
        "#train,_,_,_=train_test_split(train,train['label'],test_size=.75,shuffle=True,stratify=train['label'],random_state=160639)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQJb1Ba9-tlg",
        "outputId": "3b022522-21c9-47bd-cfca-ac337e9f873a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzgWkCpZ-wv6",
        "outputId": "2aeb9eb5-aee0-4cb7-8282-c73d49dc6fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "edaf8032e04e435d9f8cd4adb289a30d",
            "617bbf1551b34919ae77ed9c1166185f",
            "b10b26842b544ec7872b79985f006f12",
            "9c08a46dff3c4771a1937a67c1363bb2",
            "e741c555d77540368e251ce61f5eaee1",
            "62de3863aeff4b51a540be04fffcb849",
            "903a18131696402c84ff4c07dcad8c75",
            "13a5d3f29f054031b7d0c0ff7f00853b",
            "18e7c4123ebf42ef8f920de025b71469",
            "ce345b412f1b45a4bb6333ec5fb356b0",
            "94bcf4eeaa3642bc9eee21b7b5b8be85",
            "5be013653ba74945a87205117e285b3d",
            "583d99895af14b818fd1792409b24aa2",
            "7d9e497f65b44eb5afb41fa25baf6506",
            "78ebf0a46b79437b98855cb9f16c6a84",
            "d282d647ec354632bf0242e66cf650b6"
          ]
        }
      },
      "source": [
        "CONFIG = {\n",
        "    'MAX_LEN':64,\n",
        "    'TRAIN_BATCH_SIZE':32,\n",
        "    'VALID_BATCH_SIZE':32,\n",
        "    'EPOCHS':3,\n",
        "    'TOKENIZER':RobertaTokenizer.from_pretrained('roberta-base',lowercase=True,truncation=True)\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edaf8032e04e435d9f8cd4adb289a30d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18e7c4123ebf42ef8f920de025b71469",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8se-ErM-2cK"
      },
      "source": [
        "import random\n",
        "from random import randint\n",
        "import numpy as np\n",
        "SEED_VAL  = 1000\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "def seed_all(SEED):\n",
        "  random.seed(SEED_VAL)\n",
        "  np.random.seed(SEED_VAL)\n",
        "  torch.manual_seed(SEED_VAL)\n",
        "  torch.cuda.manual_seed_all(SEED_VAL)\n",
        "  os.environ['PYTHONHASHSEED'] = str(SEED_VAL)\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oPsZZ8F-306"
      },
      "source": [
        "class CustomRoberta(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomRoberta, self).__init__()\n",
        "        self.num_labels = 3\n",
        "        self.roberta = transformers.RobertaModel.from_pretrained(\"roberta-base\", output_hidden_states=False, num_labels=self.num_labels)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.classifier = nn.Linear(768, self.num_labels)\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids=None,\n",
        "                attention_mask=None,\n",
        "                position_ids=None,\n",
        "                head_mask=None,\n",
        "                inputs_embeds=None):\n",
        "\n",
        "        _, o2 = self.roberta(input_ids,\n",
        "                               attention_mask=attention_mask,\n",
        "                               position_ids=position_ids,\n",
        "                               head_mask=head_mask,\n",
        "                               inputs_embeds=inputs_embeds)\n",
        "        o2 = self.dropout(o2)\n",
        "        logits = self.classifier(o2)       \n",
        "        outputs = logits\n",
        "        return outputs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMX8k2o5-8Ba"
      },
      "source": [
        "class RobertaDataset:\n",
        "  def __init__(self,tweet,target=None,task='train'):\n",
        "    self.tweet= tweet\n",
        "    self.target = target\n",
        "    self.tokenizer = CONFIG['TOKENIZER']\n",
        "    self.max_len = CONFIG['MAX_LEN']\n",
        "    self.task = task\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweet)\n",
        "\n",
        "  def __getitem__(self,item):\n",
        "    tweet = str(self.tweet[item])\n",
        "    tweet = ' '.join(tweet.split())\n",
        "\n",
        "\n",
        "    inputs = self.tokenizer.encode_plus(tweet,\n",
        "                                        max_length=self.max_len,\n",
        "                                        pad_to_max_length=True,\n",
        "                                        add_special_tokens=True,\n",
        "                                        truncation=True)\n",
        "    ids = inputs['input_ids']\n",
        "    mask = inputs['attention_mask']\n",
        "    \n",
        "\n",
        "\n",
        "    to_return= {\n",
        "        'ids':torch.tensor(ids,dtype=torch.long),\n",
        "        'mask':torch.tensor(mask,dtype=torch.long),\n",
        "    }\n",
        "    if (self.task=='train'):\n",
        "\n",
        "      to_return.update({'target':torch.tensor(self.target[item])})\n",
        "\n",
        "    return to_return"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFoFi7To-_CK"
      },
      "source": [
        "def loss_fn(outputs,targets):\n",
        "  criterion =  nn.CrossEntropyLoss()\n",
        "  return criterion(outputs,targets)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7afTh7B_Bo6"
      },
      "source": [
        "def train_fn(data_loader,model,optimizer,device,sc=None):\n",
        "  model.train()\n",
        "  tot_loss = 0\n",
        "  for bi, d in enumerate(data_loader):\n",
        "    ids = d['ids']\n",
        "    mask = d['mask']\n",
        "    targets = d['target']\n",
        "\n",
        "    #send them to cuda gpu \n",
        "    ids = ids.to(device,dtype=torch.long)\n",
        "    mask = mask.to(device,dtype=torch.long)\n",
        "   \n",
        "    targets = targets.to(device,dtype=torch.long)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(\n",
        "        ids,\n",
        "        mask,\n",
        "    )\n",
        "    \n",
        "    loss = loss_fn(outputs,targets)\n",
        "    tot_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if sc:\n",
        "      sc.step()\n",
        "  \n",
        "  print(\"Training loss for this epoch: \",tot_loss/len(data_loader))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqkIiqcR_Gda"
      },
      "source": [
        "def eval_fn(data_loader,model,device):\n",
        "  model.eval()\n",
        "  fin_targets = []\n",
        "  fin_outputs =[]\n",
        "  tot_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for bi, d in enumerate(data_loader):\n",
        "      ids = d['ids']\n",
        "      mask = d['mask']\n",
        "      \n",
        "      targets = d['target']\n",
        "\n",
        "      #send them to cuda gpu \n",
        "      ids = ids.to(device,dtype=torch.long)\n",
        "      mask = mask.to(device,dtype=torch.long)\n",
        "      \n",
        "     \n",
        "      targets = targets.to(device,dtype=torch.long)\n",
        "      \n",
        "      \n",
        "\n",
        "      outputs = model(\n",
        "          ids,\n",
        "          mask\n",
        "      )\n",
        "\n",
        "      loss = loss_fn(outputs,targets)\n",
        "      tot_loss+=loss.item()\n",
        "      fin_targets.extend(targets.cpu().detach().numpy())\n",
        "      fin_outputs.extend(torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "  return fin_outputs,fin_targets,tot_loss/(len(data_loader))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uCvPsBU_Yu1"
      },
      "source": [
        "#test = pd.read_csv('test.csv')\n",
        "test_dataset = RobertaDataset(\n",
        "    tweet=test.text.values,\n",
        "    task='test'\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CONFIG['TRAIN_BATCH_SIZE'],\n",
        "    num_workers=4\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdrbSkOZ_j3e"
      },
      "source": [
        "def predict_fn(model):\n",
        "  fin_outputs = []\n",
        "  with torch.no_grad():\n",
        "    for bi, d in enumerate(test_data_loader):\n",
        "      ids = d['ids']\n",
        "      mask = d['mask']\n",
        "  \n",
        "      #send them to cuda gpu \n",
        "      ids = ids.to(device,dtype=torch.long)\n",
        "      mask = mask.to(device,dtype=torch.long)\n",
        "      \n",
        "     \n",
        "      outputs = model(\n",
        "          ids,\n",
        "          mask\n",
        "      )\n",
        "      fin_outputs.append(torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "      alls = np.vstack(fin_outputs)\n",
        "\n",
        "  return alls"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2HQUP29_ng_"
      },
      "source": [
        "def run_folds():\n",
        "    total_folds=1\n",
        "    all_preds = []\n",
        "    losses = []\n",
        "    seed_all(SEED_VAL)\n",
        "    dfx = train.fillna(\"none\")\n",
        "    dfx['label'] = dfx['label'].factorize()[0]\n",
        "    df_train,df_valid,_,_=train_test_split(dfx,dfx['label'],test_size=.17,shuffle=True,stratify=dfx['label'],random_state=160639)\n",
        "    for i in range(1):\n",
        "    #fold=StratifiedKFold(n_splits=total_folds, shuffle=True)\n",
        "    #for i,(train_index, test_index) in enumerate(fold.split(dfx,dfx['label'])):\n",
        "     # print(f'FOLD {i+1}/{total_folds}')\n",
        "      #df_train = dfx.iloc[train_index]\n",
        "      #df_valid = dfx.iloc[test_index]\n",
        "\n",
        "      train_dataset =RobertaDataset(\n",
        "          tweet=df_train.text.values,\n",
        "          target=df_train.label.values,\n",
        "          task='train'\n",
        "      )\n",
        "\n",
        "      train_data_loader = torch.utils.data.DataLoader(\n",
        "          train_dataset,\n",
        "          batch_size=CONFIG['TRAIN_BATCH_SIZE'],\n",
        "          num_workers=4\n",
        "      )\n",
        "\n",
        "      valid_dataset =RobertaDataset(\n",
        "          tweet=df_valid.text.values,\n",
        "          target=df_valid.label.values,\n",
        "          task='train'\n",
        "      )\n",
        "\n",
        "      valid_data_loader = torch.utils.data.DataLoader(\n",
        "          valid_dataset,\n",
        "          batch_size=CONFIG['TRAIN_BATCH_SIZE'],\n",
        "          num_workers=1\n",
        "      )\n",
        "\n",
        "      device = torch.device(\"cuda\")\n",
        "      model = CustomRoberta()\n",
        "      model.to(device)\n",
        "      \n",
        "      param_optimizer = list(model.named_parameters())\n",
        "      no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "      optimizer_parameters = [\n",
        "          {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "          {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
        "      ]\n",
        "\n",
        "      num_train_steps = int(len(df_train) / CONFIG['TRAIN_BATCH_SIZE'] * CONFIG['EPOCHS'])\n",
        "      optimizer = AdamW(optimizer_parameters, lr=1e-5)\n",
        "      \n",
        "      #scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=num_train_steps)\n",
        "\n",
        "\n",
        "      best_accuracy = 0\n",
        "      for epoch in range(CONFIG['EPOCHS']):\n",
        "          print(\"----------------EPOCH \"+str(epoch+1)+\"---------------------\")\n",
        "          train_fn(train_data_loader, model, optimizer, device#scheduler\n",
        "                  )\n",
        "          outputs,targets,losss = eval_fn(valid_data_loader ,model, device)\n",
        "          print(\"LOSS for this Epoc on val: \",losss)\n",
        "      losses.append(losss)\n",
        "      fold_preds = predict_fn(model)\n",
        "      all_preds.append(fold_preds)\n",
        "    print(\"mean losses over all folds: \",np.mean(losses))\n",
        "    return  all_preds"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoUzQEDG_tsH",
        "outputId": "43e2cbbb-25d4-4b58-d3e0-6ec0e03f69cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985,
          "referenced_widgets": [
            "28643af078e94109976e7099e0c2b85d",
            "e6f810d00389465cbd7732acd96ab922",
            "2bccf35423974cea91da0ccf1a6bc97e",
            "f15cf09fe52f445baec80c01a1e4a11d",
            "cec280df1f29444d92a418ef03236699",
            "7972f6b3116e4f62849d189418d34e7c",
            "2ad6899c374b4f3880220abebe767b42",
            "9655fb9b5be74b1297802db698df6ab1",
            "a52299719a224fffa0d9bb4706940da6",
            "8636673094284870a93f301176d89bb1",
            "64cf2ac471d94f26a69e4eb2ec995601",
            "982fddeee5a04a738089dd33a5b9bae3",
            "f1c5c13bbed444388b2978c8e0376b2f",
            "5e33c74beb1048aaa9868a37ac9d89b7",
            "41e37f135cba4ac9abd85a11aded26c5",
            "3ccf988772e94dbd922e092abbf371a8"
          ]
        }
      },
      "source": [
        "preds = run_folds()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28643af078e94109976e7099e0c2b85d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a52299719a224fffa0d9bb4706940da6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------EPOCH 1---------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for this epoch:  0.4661143212218535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS for this Epoc on val:  0.4294603568478789\n",
            "----------------EPOCH 2---------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for this epoch:  0.4212284905585761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS for this Epoc on val:  0.4290593750915085\n",
            "----------------EPOCH 3---------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for this epoch:  0.3893860901180576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS for this Epoc on val:  0.43397654039884204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean losses over all folds:  0.43397654039884204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEq_4g3D_2HR",
        "outputId": "665d6329-579c-4f69-a30f-bf55c2ff721c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds_1 = np.mean(preds,axis=0)\n",
        "preds_1.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-HIQreEXZH",
        "outputId": "80d0d47f-21f1-4452-b7f3-aba302891ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train['label'].factorize()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 0, ..., 1, 0, 1]), Int64Index([1, 0, 2], dtype='int64'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CfRZin9CpVR"
      },
      "source": [
        "preds_1[:, [1, 0]] = preds_1[:, [0, 1]] "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r8DGSYJJm7P"
      },
      "source": [
        "predictions=preds_1.argmax(axis=1)\n",
        "submission_df = pd.DataFrame(predictions, columns=['label'])\n",
        "# #write a .csv file for submission\n",
        "submission_df.to_csv('bert_trial.csv', index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tklTeFgvFtS1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}